{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](img/pycon.png)\n",
    "\n",
    "\n",
    "## Geodata processing using Python and JupyterHub\n",
    "\n",
    "Prof. Martin Christen<br/>\n",
    "mailto:martin.christen@fhnw.ch<br/>\n",
    "Twitter: @MartinChristen<br/>\n",
    "LinkedIn: https://www.linkedin.com/in/martinchristen/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation of required Modules\n",
    "\n",
    "(This tutorial requires anaconda, if you don't have it yet, download it here: https://www.anaconda.com/download/ ).\n",
    "\n",
    "If you try without anaconda: good luck!\n",
    "\n",
    "**This notebook requires Python 3.6 (or higher)** (jupyter Notebook or Jupyter Lab using Chrome)\n",
    "\n",
    "### Installing Modules (conda)\n",
    "\n",
    "Install the main modules using conda, dependencies will be resolved (gdal etc.)\n",
    "\n",
    "    conda install shapely\n",
    "    conda install fiona\n",
    "    conda install rasterio\n",
    "    conda install geopandas\n",
    "    conda install folium -c conda-forge\n",
    "    conda install ipyleaflet -c conda-forge \n",
    "    \n",
    "    \n",
    "### Jupyter Kernel for Geo ? ###\n",
    "\n",
    "\n",
    "#### Install new environment with Jupyter Kernel\n",
    "\n",
    "    conda create --name geopython36 python=3.6 -y\n",
    "    conda activate geopython36\n",
    "    conda install ipykernel -y\n",
    "    python -m ipykernel install --user --name PyConLt\n",
    "    conda install gdal matplotlib shapely fiona rasterio geopandas -y\n",
    "    conda install folium ipyleaflet -c conda-forge -y\n",
    "    \n",
    "#### List all Kernels:\n",
    "\n",
    "    jupyter kernelspec list\n",
    "    \n",
    "#### Delete kernel: \n",
    " \n",
    "    jupyter kernelspec remove GeoPython_3.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting Started with Folium & Vector Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map(location=[54.716769, 25.287379], zoom_start=16)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's open the Lithuania Polygon from GeoJson. Also display its WKT string.\n",
    "\n",
    "Note: The polygon is **highly** simplified for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from shapely.geometry import shape\n",
    "\n",
    "f = open(\"data/lithuania.geojson\")\n",
    "s = f.read()\n",
    "f.close()\n",
    "\n",
    "geojson = json.loads(s)\n",
    "lithuania = shape(geojson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CAUTION**\n",
    "\n",
    "When we look at the coordinates we see: in the file the coordinate order is **longitude, latitude** - in folium we have **latitude, longitude**\n",
    "\n",
    "Some people prefer lng,lat (x,y) instead of lat,lng (y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithuania.wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polygon on Map\n",
    "\n",
    "Now display this Polygon on the folium map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_lt = folium.Map(location=[54.716769, 25.287379], zoom_start=5)  \n",
    "folium.GeoJson(geojson).add_to(map_lt)\n",
    "map_lt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are currently at: latitude 54.716769, longitude: 25.287379\n",
    "\n",
    "We can create a Point-Object using shapely. Note we're using the lat,lng order now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "PyConLT = Point([25.287379, 54.716769])\n",
    "PyConLT.wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapely:Binary operations on shapes:\n",
    "\n",
    "- **contains** (Returns True if the interior of the object intersects the interior of the other but does not contain it, and the dimension of the intersection is less than the dimension of the one or the other.)\n",
    "- **intersects** (Returns True if the boundary and interior of the object intersect in any way with those of the other.)\n",
    "- **witin** (Returns True if the objectâ€™s boundary and interior intersect only with the interior of the other (not its boundary or exterior).\n",
    "- **touches** (Returns True if the objects have at least one point in common and their interiors do not intersect with any part of the other.)\n",
    "- **crosses** (Returns True if the interior of the object intersects the interior of the other but does not contain it, and the dimension of the intersection is less than the dimension of the one or the other.)\n",
    "- **equals** (Returns True if the set-theoretic boundary, interior, and exterior of the object coincide with those of the other.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if we are inside the Lithuania Polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyConLT.within(lithuania)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take another Point. EuroPython 2019 is in Basel, Switzerland this year (July 8 to 14). That is definitively not Lithuania..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EuroPython2019 = Point([7.599337, 47.562603])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EuroPython2019.within(lithuania)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vector Data and GeoPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/cities5k.csv', encoding=\"utf-8\", sep=\",\", header=None, low_memory=False)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Columns for Demo...\n",
    "\n",
    "We really have too many columns, to make everything easier, I just reduce to the most important ones and give some column names.\n",
    "This is all standard pandas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[[1,4,5,7,14]]\n",
    "df2.columns = [\"name\", \"lat\", \"lng\", \"type\", \"population\"]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.query(\"name == 'Vilnius'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove sections, see https://www.geonames.org/export/codes.html for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2.type != 'PPLX']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a GeoPandas Data Frame\n",
    "\n",
    "We simply need a geometry column with a shaply geometry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "geometry = [Point(pos) for pos in zip(df2['lng'], df2['lat'])]\n",
    "gdf = gpd.GeoDataFrame(df2, geometry=geometry)\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove the columns \"lat\" and \"lng\", it is redundant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.drop(['lat', 'lng'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "gdf.plot(color='green', markersize=15, figsize=(15,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "PyConLT = Point([25.287379, 54.716769])\n",
    "\n",
    "dist = gdf.distance(PyConLT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_new = gdf.copy()\n",
    "gdf_new[\"distance\"] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = gdf_new.sort_values([\"distance\"], ascending=True)\n",
    "s.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_new = gdf.copy()\n",
    "lt_mask = gdf_new.within(lithuania)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_cities = gdf_new[lt_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_cities[lt_cities.population > 20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now display cities on a folium map using markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "map_cities = folium.Map(location=[54.716769, 25.287379], zoom_start=7)\n",
    "\n",
    "def create_marker(row):\n",
    "    lng = row[\"geometry\"].x\n",
    "    lat = row[\"geometry\"].y\n",
    "    name = row[\"name\"]\n",
    "    population = str(int(row[\"population\"]))\n",
    "    folium.Marker([lat, lng], popup=f'{name}, population:{population}').add_to(map_cities)\n",
    "    \n",
    "lt_cities.apply(create_marker, axis=1)\n",
    "map_cities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Live Data & GeoPandas\n",
    "\n",
    "We're looking at the earthquake data from USGS:\n",
    "https://earthquake.usgs.gov/earthquakes/feed/v1.0/geojson.php\n",
    "\n",
    "This data is updated every minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_week.geojson\"\n",
    "#url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/significant_month.geojson\"\n",
    "#url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_month.geojson\"\n",
    "\n",
    "data = requests.get(url)\n",
    "file = open(\"earthquakes.geojson\",\"wb\")\n",
    "file.write(data.content)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "eq_gdf = gpd.read_file(\"earthquakes.geojson\")\n",
    "eq_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simplify the output and only take most important rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = eq_gdf[[\"time\",\"mag\", \"place\",\"geometry\"]].copy()\n",
    "eq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the histogramm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq.mag.hist(bins=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps in UTC are not really human readable...\n",
    "Let's convert them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "data = []\n",
    "for row in range(0,len(eq)):\n",
    "    time = eq.iloc[row].time\n",
    "    t = str(datetime.fromtimestamp(time/1000.0, timezone.utc))\n",
    "    data.append(t)\n",
    "    \n",
    "eq[\"time_utc\"] = data\n",
    "eq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = eq.drop(['time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Natural Earth Dataset with all Polygons of all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfAdmin0 = gpd.read_file(\"data/ne_10m_admin_0_countries/ne_10m_admin_0_countries.shp\", encoding=\"utf-8\")\n",
    "gdfAdmin0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = gdfAdmin0.plot(figsize=(15,9), color=\"black\")\n",
    "eq.plot(ax=countries, color=\"red\", markersize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq.sort_values([\"mag\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. More GeoPandas Fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdfAdmin0 = gpd.read_file(\"data/ne_10m_admin_0_countries/ne_10m_admin_0_countries.shp\", encoding=\"utf-8\")\n",
    "gdfAdmin0.head()\n",
    "\n",
    "lt = gdfAdmin0[gdfAdmin0['NAME'] == \"Lithuania\"]\n",
    "lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_merc = lt.to_crs({'init': \"epsg:3857\"}) # reproject to web mercator\n",
    "lt_merc.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative we can always use Folium to display output. We can **directly** convert geopandas to geojson\n",
    "\n",
    "Please note: we always have to use WGS84 (geopgraphic coordinates!) wghen using folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "center = [54.716769, 25.287379] \n",
    "map_lt = folium.Map(center, zoom_start=5)   \n",
    "\n",
    "folium.GeoJson(lt).add_to(map_lt)\n",
    "\n",
    "map_lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "center = [54.716769, 25.287379] \n",
    "map_lt = folium.Map(center, zoom_start=5)   \n",
    "\n",
    "folium.GeoJson(lt,style_function=lambda feature: {\n",
    "        'fillColor': 'green',   # you can also replace this with functions with feature as argument\n",
    "        'color': 'black',\n",
    "        'weight': 2,\n",
    "        'dashArray': '5, 5'\n",
    "    }).add_to(map_lt)\n",
    "\n",
    "map_lt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Raster Data with rasterio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "dataset = rasterio.open('data/BlueMarble.tif', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.count # number of raster bands, in our case 3 for r,g,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.width, dataset.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.transform  # affine transformation pixel to crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.transform * (0, 0)    # Pixel to CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~dataset.transform #Â inverse affine transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~dataset.transform * (0,0) # CRS to Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px, py = ~dataset.transform * (25.287379, 54.716769) # Our Location to Pixel\n",
    "print(px,py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = dataset.read(1)\n",
    "g = dataset.read(2)\n",
    "b = dataset.read(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = np.dstack((r,g,b))  # stack r,g,b so we can display it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,9))\n",
    "ax.imshow(rgb, interpolation='nearest')\n",
    "ax.plot(px,py, 'ro'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyConLt",
   "language": "python",
   "name": "pyconlt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
